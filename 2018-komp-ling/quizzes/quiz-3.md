# Quiz 3 by Nikolaeva Anna
##### 1.	a) Give an argument for why constraint grammar rules are more valuable
Подход, основанный на constraint grammar rules, позволяет отсеять невозможные последовательности POS-тегов в данном языке. Он позволяет построить хорошую морфологическую модель для конкретного языка, при этом правила можно уточнять, можно добавлять новые правила и улучшать работу теггера-дизамбигуатора так, чтобы он всегда старался выбирать только один разбор предложения по частям речи и другим грамматическим показателям, избавляясь от амбигуации. 
На мой взгляд, этот подход с правилами больше подходит для тех лингвистов, которые очень хорошо понимают структуру языка, для которого создается дизамбигуатор, иначе будет трудно быстро написать эффективные правила, учитывающие самые разные нюансы. Также constraint grammar rules для некого языка удобно использовать, если уже есть основанные на правилах дизамбигуаторы для родственных ему языков.  
Также, по моим впечатлениям от лекции и прочитанных материалов, правила могут быть более эффективны для дизамбигуации флективных языков с относительно свободным порядком слов, как русский, поскольку в правилах можно оперировать всеми возможными грамматическими показателями слова (род, число, падеж и т.д.). Ведь в русском языке наиболее частотна не частеречная неоднозначность, а неоднозначность именно этих показателей. С другой стороны, для языков типа английского, на мой взгляд, такие сложные правила не нужны и будет достаточно обычной Скрытой Марковской модели (и тогда уже проще разметить корпус, ведь разметка будет не такой сложной). 
##### b) Give an argument for why corpus annotation and HMM training is more valuable
Главное преимущество Скрытой Марковской модели в том, что, написав ее один раз, ее можно применять к разным языкам, а размеченный корпус впоследствии смогут использовать другие исследователи. Модель основана на вычислении вероятностей данных в train-сете, и поэтому необязательно глубоко и интуитивно разбираться в грамматической структуре данного языка (хотя эти знания понадобятся тем, кто будет размечать корпус). Также эта модель ориентирована на полный морфологический парсинг: то есть, всегда выдается, если я правильно понимаю, только один наиболее вероятный конечный вариант морфологического разбора. 
Однако для языков разного типа модель придется дорабатывать: например, для агглютинативного турецкого языка одним тегом будет выступать не просто частеречный тег, а некий сет из разных тегов, обозначающих морфемы, и, например, transition probabilities будут рассчитываться уже для этих сетов тегов. 
Также не так сложно доработать марковскую модель, чтобы она тегировала и те слова, которых нет в train-корпусе (я пока не видела примеров того, как можно включить неизвестные слова в модель, основанную только на constrain rules). 

##### Which would you prefer?
Думаю, для разных типов языков и целей можно использовать и тот, и другой подход. Возможно, для лингвистики в целом и для последующих исследований всегда будет полезнее сначала собрать и разметить корпус для нового языка и попробовать HMM. Если данных для этого метода будет недостаточно, можно попробовать правила. 
##### 2. Can the two systems be used together? Explain.
Да, две эти системы могут использоваться вместе. Например, теггер, основанный на правилах, можно использовать сначала, чтобы отсеять невозможные теги для каждого слова, а потом уже применить HMM-теггер, чтобы выбрать наиболее вероятные из оставшихся тегов. Объединение нескольких подходов для морфологической дизамбигуации эффективно тогда, когда разные теггеры имеют разные типы ошибок (complementary errors).  
Также существуют модели, которые объединяют правила и машинное обучение с учителем, как при HMM – это Transformation-Based Tagging. Его суть в том, что сначала всем словам из тест-сета присваиваются наиболее частотные теги этих слов из размеченного по тегам корпуса. Затем на основе данных из тренировочного сета автоматически по шаблонам составляются правила исправления тегов, от более общего и грубого правила к более конкретным правилам. Правила применяются последовательно на основе расчетов: чем больше тегов исправляется посредством правила, тем это правило выполняется раньше остальных.  
##### 3. Give a sentence with morphosyntactic ambiguity. What would you expect a disambiguator to do in this situation? What can you do?
I want to _book_ a ticket. 

I don’t like this _book_. 

Мы хотим, чтобы наш теггер в первом случае разметил «book» как глагол, а во втором – как существительное. Мы могли бы использовать биграммную или триграммную Скрытую Марковскую модель, которая рассчитала бы следующие произведения вероятности и вывела нам максимальную:

I want to _book_ a ticket. 

- P (book | VERB ) * P ( VERB | TO (inf) ) 
- P ( book | NOUN ) * P ( NOUN | TO (inf) )

I don’t like this _book_. 

- P (book |  VERB) * P (VERB | DET) 
- P ( book | NOUN) * P (NOUN | DET) 

Если мы делаем подсчеты на основе большого размеченного корпуса, то наиболее вероятными окажутся правильные варианты. 
Или же мы могли бы написать constraint grammar rules для слова book, например: 
- __remove NOUN if (-1 TO(inf))__, т.е. удаление вариант слова с тегом NOUN, если предыдущий тег – частица to, которая ставится перед инфинитивом глагола (но не предлог to). 
- __remove VERB if (-1* DET)__, т.е. удаление варианта слова с тегом VERB, если предыдущий тег – это артикль или другой определитель существительного

Я интуитивно понимаю оба способа, но первый способ лично мне пока кажется легче реализовать в коде, поскольку для второго нужно иметь некие инженерные навыки, которые я еще не освоила. 
##### 4. Choose several (>2) quantities that evaluate the quality of a morphological disambiguator, and describe how to compute them. Describe what it would mean to have disambiguators which differ in quality based on which quantity is used. Suggested quantities: false positive, false negative, precision, recall.
На мой взгляд, морфологический дизамбигуатор можно оценивать по-разному, это зависит от типа дизамбигуатора. Например, если учитывать, что дизамбигуатор получает на вход возможные пары слово-тег (или слово-последовательность тегов) и должен выбрать из них один разбор, то мы можем считать, что у нас не будет ложно-отрицательных значений, поскольку модель сразу распознает, какие именно слова нужно дизамбигуировать -- у них будет несколько вариантов тега. В этом случае мы можем оценивать точность дизамбигуатора только по истинно-положительным и ложно-положительным значениям. Допустим, на входе у дизамбигуатора 100 слов, из них 10 слов – с амбигуацией. При сравнении с золотым стандартом оказалось, что 8-ми словам дизамбигуатор приписал правильный тег (=true positives), 2-м из них – неправильный (=false positives). Получается, что точность дизамбигуатора составит 80%: true positives / (false positives + true positives). Поскольку false negatives = 0, полнота (recall) составит 100%: true positives / (true positives + false negatives).  

Если же дизамбигуатор получает на вход один вариант разобранных по POS-тегам слов в предложениях, где, например, каждому слову соответствует самый частотный в корпусе для этого слова тег, и дизамбигуатору надо исправить правилами или как-то еще неподходящие, хотя и частотные теги, тут можно использовать больше метрик:
- false positives – это когда не надо было исправлять тег на менее частотный, а дизамбигуатор исправил. 
- false negatives – когда надо было исправить тег на менее частотный, а дизамбигуатор не исправил.  
- true positives – тег был исправлен, где нужно.
- true negatives – тег не был исправлен, где не было нужно. 

Тогда мы можем подсчитать precision и recall соответствующими формулами. Эти метрики должны соотноситься между собой: плохо, если у нас будет очень маленькая полнота при высокой точности и наоборот. 
•	Precision: true positives / (false positives + true positives)
•	Recall: true positives / (true positives + false negatives)
Можно гармонизировать эти значения через F-меру. 

Думаю, что такой метод оценки можно использовать и тогда, когда у нас 2 в 1, т.е. мы имеем в одной модели и теггер, и дизамбигуатор.

Также качество дизамбигуатора могла бы продемонстрировать оценка того, как он растегировал целые предложения. Тогда это будет просто метрика _accuracy_: число правильно растегированных предложений / число всех предложений в тест-сете. Однако, на мой взгляд, предыдущий способ оценки лучше покажет, как дизамбигуатор справляется с морфологической дизамбигуацией (особенно если в нескольких предложениях сконцентрировано сразу несколько слов с амбигуацией).
##### 5. Give an example where an n-gram HMM performs better than a unigram HMM tagger.
“The old man the boat.” – здесь, чтобы правильно распарсить первую часть предложения (что old – существиельное, а man – глагол), нужно знать, что позднее встретится «the boat». 

«Сказка о пойманной моряком золотой, но маленькой рыбке» - здесь я попробовала придумать сложный случай амбигуации. «Золотой» находится на некотором расстоянии от предлога «о», который определяет падеж именной группы, но также и на некотором расстоянии от слова «рыбке», с которым согласуется. Поэтому неочевидно, как unigram HMM tagger распарсит прилагательное «золотой» - как прилагательное в именительном падеже мужского рода или в творительном, дательном или предложном падеже женского рода.  Если учитывать больше слов, окружающих «золотой», то точность снятия морфологической омонимии должна повыситься. 
