*1. In the reading, it is claimed that to implement a morphological disambiguator for an unseen language, it takes roughly the same amount of time whether annotating a corpus to train on versus writing constraint grammar rules.*  

*Give an argument for why constraint grammar rules are more valuable*  

— оптимальный вариант для редких языков, корпус текстов на которых недостаточно велик  
— есть возможность использовать их (с некоторыми модификациями) для группы близкородственных языков   
— хорошая интерпретируемость и прозрачность — довольно легко исправлять ошибки, потому что можешь сделать вывод, откуда они берутся   


*b) Give an argument for why corpus annotation and HMM training is more valuable*  

— не нужно явно формулировать множество правил, исключений: в модели используются статистические методы (кроме того, если правил очень много, система усложняется и одни правила могут вступать в противоречие с другими — здесь такой проблемы нет)  
— универсальна, может применяться к любым языкам  
— не требуется глубоких лингвистических знаний (размечать корпус могут и не профессиональные лингвисты, а например, студенты)  


*Which would you prefer?*  

Зависит от задачи и языка: например, в случае с редкими языками хорошо себя проявил подход, основанный на правилах. Если же размеры корпуса позволяют, вполне можно использовать HMM (это в принципе полезно для самых разных задач в области языка — иметь размеченный корпус). Можно также комбинировать эти два подхода, чтобы скомпенсировать ошибки каждого.   


*2. Can the two systems be used together? Explain.*  

Да, могут: скажем, сначала применяем правила > исключаем невозможные теги для слов >   обращаемся к HMM, чтобы выбрать наиболее вероятные теги из оставшихся возможных. 
Стоит также упомянуть Brill’s rule-based PoS tagger (и другие подобные): это модель, основанная на правилах (или «трансформациях»), которые, однако, извлекаются из обучающего размеченного корпуса без участия эксперта. Это гибридный подход: сначала используются статистические методы для извлечения информации из обучающего корпуса, потом используется программа для обучения правилам, которые уменьшают ошибки (сначала применяются более общие правила, которые исправляют большее количество тегов, затем всё более и более специфичные).   


*3. Give a sentence with morphosyntactic ambiguity. What would you expect a disambiguator to do in this situation? What can you do?*  

Воспользуюсь предложением, двусмысленность которого обыгрывает Баум в «Волшебнике страны Оз»:

`The peasants are revolting.`  

«Revolting» может быть как прилагательным, так и глаголом. И для дизамбигуации это поистине сложное предложение: без дополнительного контекста трудно сделать выбор.  Оба варианта вероятны, однако, возможно, дизамбигуатор посчитает, что «revolting» после «are» реже употребляется в качестве прилагательного, чем в качестве глагола — то есть вероятнее вариант глагола («revolting» в роли прилагательного всё же чаще употребляется перед существительным и после предлога, как кажется в первом приближении, когда ищешь это слово/словосочетание в корпусе). Но, конечно, чтобы сделать однозначный вывод, нужен контекст (если опустить тот факт, что благодаря моим экстралингвистическим знаниям я могу сделать в данном случае вывод о намеренной языковой игре).   


*4. Choose several (>2) quantities that evaluate the quality of a morphological disambiguator, and describe how to compute them. Describe what it would mean to have disambiguators which differ in quality based on which quantity is used.*

*Suggested quantities: false positive, false negative, precision, recall.*  

Допустим, мы берем случай, когда дизамбигуатор должен сделать выбор: оставить имеющийся тег (самый частотный) или изменить его. У нас есть по 2 возможности для верного и фактического ответов: 
— true positive: случаи, когда дизамбигуатор изменил тег, как и следовало  
— false positive (ошибки первого рода): случаи, когда дизамбигуатор изменил тег на менее частотный, хотя его нужно было оставить   
— true negative: случаи, когда дизамбигуатор не изменил тег, хотя следовало  
— false negative (ошибки второго рода): случаи, когда дизамбигуатор не изменил тег на менее частотный, хотя его нужно было изменить  


— precision = true positives / (true positives + false positives)  
— recall = true positives / (true positives + false negatives)  

Precision можно интерпретировать как долю тегов, измененных дизамбигуатором и которые при этом действительно нужно было изменить, а recall показывает, какую долю тегов, подлежащих изменению, из всех тегов, которые нужно было исправить, нашел дизамбигуатор. По отдельности эти метрики брать нельзя (если почти всё изменить, будет высокий recall, но низкий precision; если почти ничего не изменить — наоборот), лучше смотреть F-меру, которая комбинирует обе. 

Если мы рассматриваем задачу как многоклассовую классификацию (выбор части речи из нескольких возможных), то для каждой части речи получаем:

— false positive (ошибки первого рода): количество токенов, которых дизамбигуатор ошибочно определил как данную часть речи  
— false negative (ошибки второго рода): количество токенов этой части речи, для которых дизамбигуатор верный тег не определил  

Также будем использовать F-меру и следить за метрикой каждого из классов.   


*5. Give an example where an n-gram HMM performs better than a unigram HMM tagger.*  

`These desire paths are going to spring up faster than ever.`

Если будем использовать unigram HMM tagger, он не будет учитывать контекст и выдаст, что spring —  существительное (и действительно, это слово чаще всего употребляется в значении «весна»). Если же взять n-gram HMM, то он должен определить, что это глагол: «to» перед словом «spring» и «up» после него значительно повышают вероятность того, что это именно глагол. 