{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import statistics\n",
    "from os import listdir, remove\n",
    "from os.path import isfile, join\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_characters_words(path):\n",
    "    word_number, char_number = 0, 0\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    print(onlyfiles)\n",
    "    \n",
    "    paragraph_len = []\n",
    "    \n",
    "    for filename in onlyfiles:\n",
    "        if filename != \"count_characters_words.py\":\n",
    "           # with open(root[2:]+\"/\"+filename, \"r\") as f:\n",
    "            print(filename)\n",
    "            with open(join(path,filename),\"r\") as f:\n",
    "                count_characters = 0\n",
    "                count_words = 0 \n",
    "                #paragraphs\n",
    "                paragrah_inside_file = []\n",
    "                try:\n",
    "                    paragraph = re.split('\\n',f.read())\n",
    "                    #print(par)\n",
    "                    for par in paragraph:\n",
    "                        sent_text = sent_tokenize(par) # this gives us a list of sentences\n",
    "                        print(sent_text,\"###\",'len = ', len(sent_text))\n",
    "                        if (len(sent_text) > 0 ):\n",
    "                            paragraph_len.append(len(sent_text))\n",
    "                            paragrah_inside_file.append(len(sent_text))\n",
    "                            #print(len(sent_text))\n",
    "                        for i in par:\n",
    "                            count_characters += 1\n",
    "                        for word in par.split():\n",
    "                            count_words += 1\n",
    "                except ValueError:\n",
    "                    print(\"SMTH_WRONG\")\n",
    "                \n",
    "                print (filename, count_words, \"word\", count_characters, \"symb\", paragrah_inside_file, \"sentences \")\n",
    "                word_number, char_number = word_number + count_words, char_number + count_characters\n",
    "    print(\"median of sentences in pararpah = \", statistics.median(paragraph_len))\n",
    "    print (\"total in direct\", path + \":\", word_number, \"words\", char_number, \"symb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБОАБОТАТЬ ТЕКСТЫ С. УБРАТЬ НОВЫЕ СТРОКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(\"C://input/b_modified//\") if isfile(join(\"C://input//b_modified\", f))]  \n",
    "for filename in onlyfiles:\n",
    "    \n",
    "    with open(join(\"C://input//b_modified\",filename),\"r\", encoding = \"utf-8\") as f:\n",
    "        try:\n",
    "            paragraphs = re.split('\\n',f.read())\n",
    "        except:\n",
    "            paragraphs = [line.rstrip('\\n') for line in open(join(\"C://input//b_modified\",filename))]\n",
    "        paragraphs = list(filter(None, paragraphs))\n",
    "        new_text = []\n",
    "        new_line = ''\n",
    "        #print(paragraphs)\n",
    "        for par in paragraphs:\n",
    "            #print(par,par[-1] )\n",
    "            if(par[-1] != '.' and par[-1]!= '?' and par[-1] != '!'):\n",
    "                #print('necess stop sign nf', par)\n",
    "                if new_line:\n",
    "                    new_line += ' ' + par\n",
    "                else:\n",
    "                    new_line += par\n",
    "            else:\n",
    "                #print('normal line', par)\n",
    "                if new_line:\n",
    "                    new_line += ' ' + par\n",
    "                else:\n",
    "                    new_line += par\n",
    "                new_text.append(new_line)\n",
    "                new_line = ''\n",
    "       # for t in new_text:\n",
    "           # print (t,'\\n')\n",
    "        #print(new_text)\n",
    "\n",
    "        with open(join(\"C://input//b_modified/b_no_n\",filename),\"w+\", encoding = \"utf-8\") as edited_file:\n",
    "                    #print(\"writing_started\")\n",
    "                    for unit in new_text:\n",
    "                        str_unit = ''.join(unit)\n",
    "                        edited_file.write(str_unit +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get rid of ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(path,output_path,level):\n",
    "    text = []\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    stop = 0 \n",
    "    \n",
    "    \n",
    "    for filename in onlyfiles:\n",
    "        #print(\"processing file\" , filename)\n",
    "        with open(join(path,filename),\"r\", encoding = \"utf-8\") as f:\n",
    "            try:\n",
    "                paragraphs = re.split('\\n',f.read())\n",
    "            except:\n",
    "                paragraphs = [line.rstrip('\\n') for line in open(join(path,filename))]\n",
    "            paragraphs = list(filter(None, paragraphs))\n",
    "            current_unit = []\n",
    "            current_unit_length = 0\n",
    "            for par in paragraphs:\n",
    "                sent_text = sent_tokenize(par) # this gives us a list of sentences\n",
    "                #print(sent_text,\"###\",'len = ', len(sent_text))\n",
    "                \n",
    "                if current_unit_length < 10:\n",
    "                    current_unit.append(par)\n",
    "                    current_unit_length += len(sent_text)\n",
    "                elif current_unit_length >= 10:\n",
    "                    text.append(current_unit)\n",
    "                    #print(current_unit,\"### APPENDED WITH LENGTH\", current_unit_length)\n",
    "                    \n",
    "                    current_unit = []\n",
    "                    current_unit_length = len(sent_text)\n",
    "                    \n",
    "                    current_unit.append(par)\n",
    "                    \n",
    "                \n",
    "        stop += 1\n",
    "        unit_index = 0\n",
    "    for unit in text:\n",
    "        name = str(unit_index) + \"_\" + str(level) + \".txt\"\n",
    "        with open(join(output_path, name),\"w+\", encoding = \"utf-8\") as edited_file:\n",
    "            for u in unit:\n",
    "                edited_file.write(u + ' ')\n",
    "        unit_index += 1\n",
    "\n",
    "        \n",
    "write_results (path = \"C://input/c_level//c_modified//\", output_path = \"C://input/div_by_unit//c\", level = 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results (path = \"C://input//A_MODIFIED/a_no_n/\", output_path = \"C://input/div_by_unit//a\", level = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results (path = \"C://input/b_modified/b_no_n/\", output_path = \"C://input/div_by_unit//b\", level = 'b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
