<html>
<body>

<h2>Segmentation</h2>

<p>Comparison of segtok and NLTK's Punkt.</p>

<h3>Data</h3>

<p>Extracting the text: $ python3 WikiExctractor.py --infn data.bz2 >wiki.txt</p>
<p>Shuffle: $ sort -R <wiki.txt >randomwiki.txt</p>
<p>Get 50 paragraphs: $ head -n 50 <randomwiki.txt >random50.txt</p>

<h3>segtok</h3>

<p>A rule-based Python package with two modules for sentence segmentation and word tokenization.</p>

<h3>NLTK's Punkt</h3>

<p>Machine learning sentence and word tokenizer for Python.</p>

<h3>Evaluation</h3>

<h2>Tokenization</h2>

</body>
</html>