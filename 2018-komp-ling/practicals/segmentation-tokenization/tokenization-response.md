# Report 2
## Tokenization

1) To employ the maxmatch algorithm, we first need to create a dictionary of words maxmatch would be looking for in the test sentences. For that, we've created a *create_dict.py* script, which suggests you to input the name of the conllu file to parse to collect the words and then write them to the dictionary text file you create. Dictionary is sorted from the longest word to shortest in order for the maxmatch algorithm to spend less time going over the dictionary when trying to find a word.

2) Then, I've created a script called *collect_sent.py*, which is used to extract sentences from the test conllu file, which I use later to try the maxmatch on, and the gold standart of sentences to actually see how well maxmatch would perform. In this script, I ask the user to provide the name of the conllu file and then ask them to create a .txt file for the output, first just sentences, then gold standart sentences. I use the metadata module of the conlly library to extract full sentences from each line in conllu file, and then write them to a file. Then, I take only the 'form' column from the conllu data and write down split gold standart sentences.

3) Then, I've created the *maxmatch.py* to employ the maxmatch algorithm. The algorithm itself is a copy of the one Jurafsky provided in his book. I've created a function which takes a sentence and a dictionary, goes through the sentence from the end to the beginning looking for words. Then I ask the user to provide the name of the dictionary and sentence files and use the algorithm to split the sentences.

4) The last step is evaluation of the algorithm. To evaluate how good or bad the maxmatch split the sentences into tokens, I've created the *evaluation.py* script, which asks user to provide the names of files with gold standart and parsed sentences, goes through them and compares tokens in each pair of sentences. It looks at the symbols, punctuation and spaces to determine where maxmatch was mistaken and where it was correct. If both sentences have a space in the same place, the algorithm split sentences correctly (true positive), if both sentences have a text symbol or a punctuation mark in the same place, the algorithm correctly didn't split the sentences (true negative). If the parsed sentence has a space where it shouldn't, it's false positive, and if it doesn't have a space where it should, it's false negative. Then, I've counted accuracy and f-score to see how well the algorithm did, and the results were pretty good: 
    * TruePositive: 9757, TrueNegative: 17563, FalsePositive: 1116, FalseNegative: 699 
    * Accuracy: 0.94, F-score: 0.91
