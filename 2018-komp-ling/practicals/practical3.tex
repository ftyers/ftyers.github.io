% This file was converted to LaTeX by Writer2LaTeX ver. 1.4
% see http://writer2latex.sourceforge.net for more info
\documentclass[letterpaper]{article}
\usepackage[ascii]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,textcomp}
\usepackage{color}
\usepackage{array}
\usepackage{hhline}
\usepackage{hyperref}
\hypersetup{pdftex, colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue, pdftitle=, pdfauthor=, pdfsubject=, pdfkeywords=}
% Page layout (geometry)
\setlength\voffset{-1in}
\setlength\hoffset{-1in}
\setlength\topmargin{0.7874in}
\setlength\oddsidemargin{0.7874in}
\setlength\textheight{9.4251995in}
\setlength\textwidth{6.9251995in}
\setlength\footskip{0.0cm}
\setlength\headheight{0cm}
\setlength\headsep{0cm}
% Footnote rule
\setlength{\skip\footins}{0.0469in}
\renewcommand\footnoterule{\vspace*{-0.0071in}\setlength\leftskip{0pt}\setlength\rightskip{0pt plus 1fil}\noindent\textcolor{black}{\rule{0.25\columnwidth}{0.0071in}}\vspace*{0.0398in}}
% Pages styles
\makeatletter
\newcommand\ps@Standard{
  \renewcommand\@oddhead{}
  \renewcommand\@evenhead{}
  \renewcommand\@oddfoot{}
  \renewcommand\@evenfoot{}
  \renewcommand\thepage{\arabic{page}}
}
\makeatother
\pagestyle{Standard}
\title{}
\author{}
\date{2018-11-28}
\begin{document}
First I added 

\ \ \ \ \ \ add('1+2 suffix', context[i+2][-3:])

\ \ \ \ \ \ add('i-3 word', context[i-3])

\ \ \ \ \ \ add('i-3 suffix', context[i-3][-3:])

to tagger.py and ran it on the Chinese corpus. The new tagger decreased the accuracy from 90\% to 84.7\%, which is a
loss of performance.


\bigskip

Then I deleted this part from the function

\ \ \ \ \ \ add('i-1 tag+i word', prev, context[i])

\ \ \ \ \ \ add('i-1 word', context[i-1])

\ \ \ \ \ \ add('i-1 suffix', context[i-1][-3:])

\ \ \ \ \ \ add('i-2 word', context[i-2])

\ \ \ \ \ \ add('i+1 word', context[i+1])

\ \ \ \ \ \ add('i+1 suffix', context[i+1][-3:])

\ \ \ \ \ \ add('i+2 word', context[i+2])

The new accuracy is now 86.4\%, which is better by a small margin.


\bigskip

If I get rid of the following lines from the original tagger.py,

\ \ \ \ \ \ add('i+2 word', context[i+2])

\ \ \ \ \ \ add('i-2 word', context[i-2])

the corresponding accuracy is 89.9\%, very close to the original one


\bigskip

After the following lines are added,

\ \ \ \ \ \ add('i+2 suffix', context[i+2][-3:])

\ \ \ \ \ \ add('i-2 suffix', \ context[i-2][-3:])

the accuracy remains the same as 90\%.


\bigskip

If I delete all the lines about suffixes, the accuracy does not suffer a significant loss: 88.6\%.


\bigskip

With the following lines added to the function

\ \ \ \ \ \ add('i+1 pref1', context[i+1][0])

\ \ \ \ \ \ add('i-1 pref1', context[i-1][0])

\ \ \ \ \ \ add('i+2 pref1', context[i+2][0])

\ \ \ \ \ \ add('i-2 pref1', context[i-2][0])

\ the accuracy is still 90\%.\ \ \ \ 


\bigskip

According to my knowledge of the Chinese language, most of its lexicons consists of 2 characters, some of 3. Lexicons of
more characters are either very rare or can be considered as combinations of shorter lexicons. This general observation
justifies the different accuracies of the multiple taggers tested above. When the range of forming new lexicons is
limited to 3, it analyzes the text at 90\%. If the range is set to 4 characters, the dictionary gets confused and the
accuracy drops to 84.7\%. The effect of suffixes and prefixes is insignificant, perhaps since there are no ``suffixes''
or ``prefixes'' in Chinese.


\bigskip

So far all the changes to the original code worsen its performance. It may result from the fact that the program was
designed for alphabetic languages, not for analytic languages.


\bigskip
\end{document}
